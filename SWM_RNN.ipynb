{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tIifVmlwKPe-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the preprocessed data from the CSV file\n",
        "data = pd.read_csv('/content/drive/MyDrive/SWM/preprocessed_dataset.csv')\n",
        "\n",
        "# Sample a smaller subset of the data for training\n",
        "train_data = data.sample(n=100000, random_state=42)\n",
        "\n",
        "# Split the data into testing dataset\n",
        "test_data = data[100000:]\n"
      ],
      "metadata": {
        "id": "g3N3WXwgKkyR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the \"text\" column to a string type\n",
        "train_data['text'] = train_data['text'].astype(str)\n",
        "\n",
        "# Drop any rows with missing values\n",
        "train_data.dropna(inplace=True)\n",
        "\n",
        "# Convert the \"text\" column to a string type\n",
        "test_data['text'] = test_data['text'].astype(str)\n",
        "\n",
        "# Drop any rows with missing values\n",
        "test_data.dropna(inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6E4g4scUh-p",
        "outputId": "a4065bbd-99a8-4d90-f972-bd83a38e5b4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-44618b689231>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data['text'] = test_data['text'].astype(str)\n",
            "<ipython-input-4-44618b689231>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data.dropna(inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "\n",
        "# Convert the text data into sequences of integers\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n"
      ],
      "metadata": {
        "id": "HxNVpsYcUL5c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences to make them of equal length\n",
        "max_len = 100\n",
        "train_padded_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "test_padded_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "AaCNfTKGUaGP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=32, input_length=max_len),\n",
        "    LSTM(units=64, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "ENsE5nJHVOVf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ma7vGKlqVWZ_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data\n",
        "history = model.fit(train_padded_sequences, train_data['target'], epochs=2, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp0kLiEYVZn1",
        "outputId": "ad1b677d-8105-4905-91d5-2770b8d31af8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2813/2813 [==============================] - 588s 208ms/step - loss: -92.5946 - accuracy: 2.2222e-05 - val_loss: -178.9539 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "2813/2813 [==============================] - 577s 205ms/step - loss: -258.0200 - accuracy: 0.0000e+00 - val_loss: -346.3347 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing data\n",
        "loss, accuracy = model.evaluate(test_padded_sequences, test_data['target'])\n",
        "print(f'Test loss: {loss:.3f}, test accuracy: {accuracy:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrRjI3ElVbkp",
        "outputId": "3685522a-f851-414b-b3b7-040f57ee0559"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46875/46875 [==============================] - 1325s 28ms/step - loss: -385.3641 - accuracy: 0.0000e+00\n",
            "Test loss: -385.364, test accuracy: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sample test Twitter text\n",
        "test_text = \"I am really happy today!\"\n",
        "\n",
        "# Tokenize the test Twitter text\n",
        "test_sequence = tokenizer.texts_to_sequences([test_text])\n",
        "\n",
        "# Pad the sequence to make it of equal length\n",
        "test_padded_sequence = pad_sequences(test_sequence, maxlen=max_len, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "a4q42CZg46hX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to predict the sentiment score of the test Twitter text\n",
        "score = model.predict(test_padded_sequence)\n",
        "\n",
        "# Print the predicted sentiment score\n",
        "print(f'Predicted sentiment score: {score[0][0]:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6I0arJCAIzP",
        "outputId": "c522cff8-10d6-462a-9d5b-6b2db8ad5eee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "Predicted sentiment score: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(model, open('RNN.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "RoTBf9H3ALS-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFaxVbl2G1Sh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}